{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 以Sarsa攻克迷宮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 宣告使用的套件\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 迷宮的初始狀態\n",
    "\n",
    "# 宣告圖的大小與圖的變數名稱\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = plt.gca()\n",
    "\n",
    "# 繪製紅色牆壁\n",
    "plt.plot([1, 1], [0, 1], color='red', linewidth=2)\n",
    "plt.plot([1, 2], [2, 2], color='red', linewidth=2)\n",
    "plt.plot([2, 2], [2, 1], color='red', linewidth=2)\n",
    "plt.plot([2, 3], [1, 1], color='red', linewidth=2)\n",
    "\n",
    "# 繪製代表狀態的文字S0～S8\n",
    "plt.text(0.5, 2.5, 'S0', size=14, ha='center')\n",
    "plt.text(1.5, 2.5, 'S1', size=14, ha='center')\n",
    "plt.text(2.5, 2.5, 'S2', size=14, ha='center')\n",
    "plt.text(0.5, 1.5, 'S3', size=14, ha='center')\n",
    "plt.text(1.5, 1.5, 'S4', size=14, ha='center')\n",
    "plt.text(2.5, 1.5, 'S5', size=14, ha='center')\n",
    "plt.text(0.5, 0.5, 'S6', size=14, ha='center')\n",
    "plt.text(1.5, 0.5, 'S7', size=14, ha='center')\n",
    "plt.text(2.5, 0.5, 'S8', size=14, ha='center')\n",
    "plt.text(0.5, 2.3, 'START', ha='center')\n",
    "plt.text(2.5, 0.3, 'GOAL', ha='center')\n",
    "\n",
    "# 設定繪圖範圍與塗銷刻度\n",
    "ax.set_xlim(0, 3)\n",
    "ax.set_ylim(0, 3)\n",
    "plt.tick_params(axis='both', which='both', bottom='off', top='off',\n",
    "                labelbottom='off', right='off', left='off', labelleft='off')\n",
    "\n",
    "# 於目前位置S0繪製綠色圓形\n",
    "line, = ax.plot([0.5], [2.5], marker=\"o\", color='g', markersize=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定一開始採用何種策略的參數theta_0\n",
    "\n",
    "# 列為狀態0～7、欄移動方向的↑、→、↓、←\n",
    "theta_0 = np.array([[np.nan, 1, 1, np.nan],  # s0\n",
    "                    [np.nan, 1, np.nan, 1],  # s1\n",
    "                    [np.nan, np.nan, 1, 1],  # s2\n",
    "                    [1, 1, 1, np.nan],  # s3\n",
    "                    [np.nan, np.nan, 1, 1],  # s4\n",
    "                    [1, np.nan, np.nan, np.nan],  # s5\n",
    "                    [1, np.nan, np.nan, np.nan],  # s6\n",
    "                    [1, 1, np.nan, np.nan],  # s7、※s8是終點，所以不需採用任何策略\n",
    "                    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自訂策略的參數theta轉換成行動策略pi的函數\n",
    "\n",
    "\n",
    "def simple_convert_into_pi_from_theta(theta):\n",
    "    '''單純地計算比例'''\n",
    "\n",
    "    [m, n] = theta.shape  # 取得theta的矩陣大小\n",
    "    pi = np.zeros((m, n))\n",
    "    for i in range(0, m):\n",
    "        pi[i, :] = theta[i, :] / np.nansum(theta[i, :])  # 計算比例\n",
    "\n",
    "    pi = np.nan_to_num(pi)  # 將nan轉換成0\n",
    "\n",
    "    return pi\n",
    "\n",
    "# 求得隨機採取行動的策略pi_0\n",
    "pi_0 = simple_convert_into_pi_from_theta(theta_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial action value function:\n",
      "[[       nan 0.7406554  0.00214088        nan]\n",
      " [       nan 0.07355205        nan 0.75538176]\n",
      " [       nan        nan 0.89470928 0.36536747]\n",
      " [0.15978006 0.39031219 0.22124366        nan]\n",
      " [       nan        nan 0.40384879 0.36757962]\n",
      " [0.04047048        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.72602869        nan        nan]]\n"
     ]
    }
   ],
   "source": [
    "# 設定初始的動作價值函數Q\n",
    "\n",
    "[a, b] = theta_0.shape  # 將列與欄的數字分別存入a與b\n",
    "Q = np.random.rand(a, b) * theta_0\n",
    "# * theta0可乘上每個元素，在Q為朝向牆壁的值，將該值設定為nan\n",
    "print('initial action value function:')\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建置ε-greedy法\n",
    "\n",
    "\n",
    "def get_action(s, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "\n",
    "    # 決定動作\n",
    "    if np.random.rand() < epsilon:\n",
    "        # 根據ε的機率隨機移動\n",
    "        next_direction = np.random.choice(direction, p=pi_0[s, :])\n",
    "    else:\n",
    "        # 採用Q為最大值的動作\n",
    "        next_direction = direction[np.nanargmax(Q[s, :])]\n",
    "\n",
    "    # 將動作存入index\n",
    "    if next_direction == \"up\":\n",
    "        action = 0\n",
    "    elif next_direction == \"right\":\n",
    "        action = 1\n",
    "    elif next_direction == \"down\":\n",
    "        action = 2\n",
    "    elif next_direction == \"left\":\n",
    "        action = 3\n",
    "\n",
    "    return action\n",
    "\n",
    "\n",
    "def get_s_next(s, a, Q, epsilon, pi_0):\n",
    "    direction = [\"up\", \"right\", \"down\", \"left\"]\n",
    "    next_direction = direction[a]  # 動作a的方向\n",
    "\n",
    "    # 根據動作決定下一個狀態\n",
    "    if next_direction == \"up\":\n",
    "        s_next = s - 3  # 向上移動時，狀態的數字減3\n",
    "    elif next_direction == \"right\":\n",
    "        s_next = s + 1  # 向右移動時，狀態的數字加1\n",
    "    elif next_direction == \"down\":\n",
    "        s_next = s + 3  # 向下移動時，狀態的數字加3\n",
    "    elif next_direction == \"left\":\n",
    "        s_next = s - 1  # 向左移動時，狀態的數字減1\n",
    "\n",
    "    return s_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以Sarsa更新動作價值函數Q\n",
    "\n",
    "\n",
    "def Sarsa(s, a, r, s_next, a_next, Q, eta, gamma):\n",
    "\n",
    "    if s_next == 8:  # 抵達終點的情況\n",
    "        Q[s, a] = Q[s, a] + eta * (r - Q[s, a])\n",
    "\n",
    "    else:\n",
    "        Q[s, a] = Q[s, a] + eta * (r + gamma * Q[s_next, a_next] - Q[s, a])\n",
    "\n",
    "    return Q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義以Sarsa走出迷宮的函數，輸出狀態、動作的履歷與更新之後的Q\n",
    "\n",
    "\n",
    "def goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi):\n",
    "    s = 0  # 起點\n",
    "    a = a_next = get_action(s, Q, epsilon, pi)  # 初始的行動\n",
    "    s_a_history = [[0, np.nan]]  # 記錄代理器移動軌跡的list\n",
    "\n",
    "    while (1):  # 在抵達終點之前不斷執行的迴圈\n",
    "        a = a_next  # 更新動作\n",
    "\n",
    "        s_a_history[-1][1] = a\n",
    "        # 將動作代入目前的狀態（由於是最後一個動作，所以index=-1）\n",
    "\n",
    "        s_next = get_s_next(s, a, Q, epsilon, pi)\n",
    "        # 儲存下一個狀態\n",
    "\n",
    "        s_a_history.append([s_next, np.nan])\n",
    "        # 代入下一個狀態。由於還不知道會是什麼動作，所以先設定為nan\n",
    "\n",
    "        # 給予報酬，計算下一個動作\n",
    "        if s_next == 8:\n",
    "            r = 1  # 若已抵達終點就給予報酬\n",
    "            a_next = np.nan\n",
    "        else:\n",
    "            r = 0\n",
    "            a_next = get_action(s_next, Q, epsilon, pi)\n",
    "            # 計算下一個動作a_next\n",
    "\n",
    "        # 更新價值函數\n",
    "        Q = Sarsa(s, a, r, s_next, a_next, Q, eta, gamma)\n",
    "\n",
    "        # 結束條件\n",
    "        if s_next == 8:  # 若已抵達終點，就結束程式\n",
    "            break\n",
    "        else:\n",
    "            s = s_next\n",
    "\n",
    "    return [s_a_history, Q]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回合:10\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.23991171        nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.44767913 0.22124366        nan]\n",
      " [       nan        nan 0.63147488 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.90447211        nan        nan]]\n",
      "回合:20\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.38600194        nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.57504877 0.22124366        nan]\n",
      " [       nan        nan 0.77306257 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.96669149        nan        nan]]\n",
      "回合:30\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.50617071        nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.67859094 0.22124366        nan]\n",
      " [       nan        nan 0.84412569 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.98838604        nan        nan]]\n",
      "回合:40\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.59623181        nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.74287604 0.22124366        nan]\n",
      " [       nan        nan 0.8764683  0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.99595046        nan        nan]]\n",
      "回合:50\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.65544023        nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.77775493 0.22124366        nan]\n",
      " [       nan        nan 0.89038302 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.99858801        nan        nan]]\n",
      "回合:60\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.6905401         nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.79518206 0.22124366        nan]\n",
      " [       nan        nan 0.89615444 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.99950767        nan        nan]]\n",
      "回合:70\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.70979917        nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.80341519 0.22124366        nan]\n",
      " [       nan        nan 0.89848747 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.99982834        nan        nan]]\n",
      "回合:80\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.7197646         nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.8071497  0.22124366        nan]\n",
      " [       nan        nan 0.89941276 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.99994014        nan        nan]]\n",
      "回合:90\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.72469133        nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.80879201 0.22124366        nan]\n",
      " [       nan        nan 0.89977437 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.99997913        nan        nan]]\n",
      "回合:100\n",
      "0.0\n",
      "走出迷宮的總步數為4步\n",
      "After training Q:\n",
      "[[       nan 0.12104143 0.72704018        nan]\n",
      " [       nan 0.12020872        nan 0.12013818]\n",
      " [       nan        nan 0.11998418 0.11998229]\n",
      " [0.15978006 0.80949685 0.22124366        nan]\n",
      " [       nan        nan 0.89991405 0.36757962]\n",
      " [0.11989671        nan        nan        nan]\n",
      " [0.64098158        nan        nan        nan]\n",
      " [0.1242733  0.99999272        nan        nan]]\n"
     ]
    }
   ],
   "source": [
    "# 以Sarsa攻克迷宮\n",
    "\n",
    "eta = 0.1  # 學習率\n",
    "gamma = 0.9  # 時間折扣率\n",
    "epsilon = 0.5  # ε-greedy法的初始值\n",
    "v = np.nanmax(Q, axis=1)  # 計算價值在每個狀態之下的最大值\n",
    "is_continue = True\n",
    "episode = 1\n",
    "\n",
    "while is_continue:  # 不斷執行，直到is_continue等於False為止\n",
    "#     print(\"回合:\" + str(episode))\n",
    "\n",
    "    # 遞減ε-greedy的值\n",
    "    epsilon = epsilon / 2\n",
    "\n",
    "    # 以Sarsa走出迷宮，得出移動軌跡與更新之後的Q\n",
    "    [s_a_history, Q] = goal_maze_ret_s_a_Q(Q, epsilon, eta, gamma, pi_0)\n",
    "\n",
    "    # 狀態價值的變化\n",
    "    new_v = np.nanmax(Q, axis=1)  # 計算價值在每個狀態之下的最大值\n",
    "#     print(np.sum(np.abs(new_v - v)))  # 輸出狀態價值的變化\n",
    "    v = new_v\n",
    "    if episode %10 == 0:\n",
    "        print(\"回合:\" + str(episode))\n",
    "        print(np.sum(np.abs(new_v - v)))  # 輸出狀態價值的變化\n",
    "        print(\"走出迷宮的總步數為\" + str(len(s_a_history) - 1) + \"步\")\n",
    "        print('After training Q:')\n",
    "        print(Q)\n",
    "        \n",
    "\n",
    "    # 重覆執行100回合\n",
    "    episode = episode + 1\n",
    "    if episode > 100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
